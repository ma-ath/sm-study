{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent algorithms in Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider a simple estimator of $n$ inputs and $m$ outputs described by\n",
    "\n",
    "$$\n",
    "\\bm{\\hat{y}}^{m} = \\sigma (\\textbf{W}^{m \\times n} \\textbf{x}^{n} + \\textbf{b}^{m})\n",
    "$$\n",
    "\n",
    "and a _loss function_ beween the estimator and the target data described by\n",
    "\n",
    "$$\n",
    "L = f(\\textbf{y}, \\bm{\\hat{y}})\n",
    "$$\n",
    "\n",
    "Gradient descent is an algorithm that minimizes the Loss function, that is, finds an optimal estimator $\\bm{\\hat{y}}$ for the data, by adjusting parameters $w_{ij}$ by the following recursion\n",
    "\n",
    "$$\n",
    "W[k+1] = W[k] - \\mu \\nabla W\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "016cd2178a8053b5595958e59a0d24370f913bb5fc4da5760f6ef0caa289bc0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
