{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"subspaces\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Download MNIST dataset\n",
    "emnist_train = torchvision.datasets.EMNIST('./emnist', download=True, train=True, split='digits')\n",
    "emnist_eval = torchvision.datasets.EMNIST('./emnist', download=True, train=False, split='digits')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of transforming data into [batch, image_data]\n",
    "# Tread it as [batch, H, W]\n",
    "# Create list of correct_labels for train and eval sets\n",
    "\n",
    "vector_size = 28\n",
    "\n",
    "train_data = torch.empty(len(emnist_train), vector_size, vector_size)\n",
    "train_correct_labels = []\n",
    "\n",
    "eval_data = torch.empty(len(emnist_eval), vector_size, vector_size)\n",
    "eval_correct_labels = []\n",
    "\n",
    "for i in range(len(emnist_train)):\n",
    "    train_data[i] = torch.squeeze(torchvision.transforms.functional.to_tensor(emnist_train[i][0]))\n",
    "    train_correct_labels.append(emnist_train[i][1])\n",
    "\n",
    "for i in range(len(emnist_eval)):\n",
    "    eval_data[i] = torch.squeeze(torchvision.transforms.functional.to_tensor(emnist_eval[i][0]))\n",
    "    eval_correct_labels.append(emnist_eval[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, apply SVD on each individual image.\n",
    "componens_per_image = 15 # Completely arbitrary, XX bu-buh XX\n",
    "\n",
    "_, _, Vh_train = torch.linalg.svd(train_data)\n",
    "Vh_train = Vh_train[:, 0:componens_per_image, :]\n",
    "Vh_train = torch.reshape(Vh_train, [Vh_train.shape[0]*Vh_train.shape[1], Vh_train.shape[2]]).to(device)\n",
    "\n",
    "train_correct_labels = [[train_correct_labels[i]]*componens_per_image for i in range(len(train_correct_labels))]\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "train_correct_labels = flatten(train_correct_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3791dbb9346b4d5b93cd967efc2f6d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from subspaces.vector_space import VectorSpace\n",
    "_, _, Vh_eval = torch.linalg.svd(eval_data)\n",
    "Vh_eval = Vh_eval.to(device)\n",
    "\n",
    "vspace_list = []\n",
    "\n",
    "for i, image in tqdm(enumerate(Vh_eval)):\n",
    "    vspace_list.append(VectorSpace(vector_size=vector_size))\n",
    "    vspace_list[i].append(image)\n",
    "    vspace_list[i].label=eval_correct_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546ad7260bb744b598e547b16115e6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05000000074505806 0.102225\n",
      "0.10000000149011612 0.10505\n",
      "0.15000000596046448 0.1018\n",
      "0.20000000298023224 0.1016\n",
      "0.25 0.1011\n",
      "0.30000001192092896 0.1001\n",
      "0.3499999940395355 0.099975\n",
      "0.4000000059604645 0.101075\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m min_energy \u001b[39min\u001b[39;00m tqdm(min_energy_list):\n\u001b[1;32m     10\u001b[0m     \u001b[39m# Train with min_energy\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     model \u001b[39m=\u001b[39m VectorMSM(vector_size\u001b[39m=\u001b[39mvector_size)\n\u001b[0;32m---> 12\u001b[0m     model\u001b[39m.\u001b[39;49mtrain(Vh_train, train_correct_labels, min_energy\u001b[39m=\u001b[39;49mmin_energy)\n\u001b[1;32m     14\u001b[0m     \u001b[39m# Predict\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     predition_list, prediction_ratio \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval(vspace_list, eval_correct_labels)\n",
      "File \u001b[0;32m~/Projects/sm-study/subspaces/vector_sm.py:22\u001b[0m, in \u001b[0;36mVectorSM.train\u001b[0;34m(self, data, labels, min_energy)\u001b[0m\n\u001b[1;32m     20\u001b[0m     data\u001b[39m.\u001b[39munsqueeze_(\u001b[39m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39mset\u001b[39m \u001b[39m=\u001b[39m VectorSet(vector_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvector_size)\n\u001b[0;32m---> 22\u001b[0m \u001b[39mset\u001b[39;49m\u001b[39m.\u001b[39;49mpopulate(data, labels)\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubset \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m\u001b[39m.\u001b[39mpca(min_energy\u001b[39m=\u001b[39mmin_energy)\n",
      "File \u001b[0;32m~/Projects/sm-study/subspaces/vector_set.py:44\u001b[0m, in \u001b[0;36mVectorSet.populate\u001b[0;34m(self, vectors, labels)\u001b[0m\n\u001b[1;32m     42\u001b[0m tensor_list \u001b[39m=\u001b[39m vectors\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     43\u001b[0m lt \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(labels, tensor_list)\n\u001b[0;32m---> 44\u001b[0m lt \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(lt)\n\u001b[1;32m     45\u001b[0m sorted_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([i \u001b[39mfor\u001b[39;00m _, i \u001b[39min\u001b[39;00m lt])\n\u001b[1;32m     46\u001b[0m sorted_labels \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, _ \u001b[39min\u001b[39;00m lt]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from subspaces.vector_msm import VectorMSM\n",
    "from subspaces.vector_space import VectorSpace\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "min_energy_list = torch.linspace(0.05, 1, 20)\n",
    "ratio = []\n",
    "\n",
    "for min_energy in tqdm(min_energy_list):\n",
    "    # Train with min_energy\n",
    "    model = VectorMSM(vector_size=vector_size)\n",
    "    model.train(Vh_train, train_correct_labels, min_energy=min_energy)\n",
    "\n",
    "    # Predict\n",
    "    predition_list, prediction_ratio = model.eval(vspace_list, eval_correct_labels)\n",
    "    print(float(min_energy), prediction_ratio)\n",
    "    ratio.append(prediction_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(min_energy_list.numpy(), ratio, 'r--')\n",
    "plt.title(\"Correct predictions over minimum energy preserved on SVD\")\n",
    "plt.xlabel(\"minimum energy preserved on SVD\")\n",
    "plt.ylabel(\"prediction ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code doesn't make sense!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
